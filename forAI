Developing a Well-Reasoned Response to a
Moral Problem in Scientific Research1
Muriel J. Bebeau
University of Minnesota
Introduction
Every day you make decisions about what to do. Some decisions are just matters of preference that have no moral implications, like whether you would rather wear a red or green sweater,
or whether you would prefer an apple to an orange. Even technical questions, such as whether to
use a flask or a beaker, or a pair of pliers or a wrench to accomplish a given task, may be simply
matters of preference. However, when the exercise of preference somehow affects the welfare of
others, moral questions arise. One of the problems for persons entering a profession, such as
science, is that they may not recognize when choices about technical matters have moral implications. One purpose of instruction in research ethics is to alert future professionals to such situations.
In most cases, when moral questions arise, you do not wonder what you should do. You
clearly know what you ought to do — even though you may feel compelling pressures not to
follow through and do it. You may question whether you can escape the consequences of not
following through, but you do not question what is right. As an educated person, you rely on
knowledge of existing laws or even intuition to tell you what to do, without necessarily reflecting
on why a given act is right or wrong. As law-abiding citizens, we recognize that we can be held
accountable for our actions and that even ignorance of an existing rule or law does not exempt us
from its consequences, should we break it. For the most part, each of us functions pretty well
without giving much thought to the reasons a particular act, such as stealing or cheating, is
wrong. Knowing the rules and laws is essential for maintaining a law-oriented society, but reflecting on the reasons for those rules and laws may not be.
However, there are some situations and contexts in which a well-developed ability to reflect
on moral issues and to undertake ethical reasoning is crucial. For professionals in science, as well
as in other fields, skills of moral reflection are important — perhaps even essential — because new
moral problems arise as technology advances, as societal expectations change, and as the various
scientific disciplines evolve. Sometimes professionals face moral problems that were not anticipated by the profession’s existing codes of conduct and are not explicitly stated in laws and/or
procedural rules. Yet case law shows that professionals can be held accountable for their deci
sions.2
 Professionals are expected responsibly and knowledgeably to apply moral principles to
arrive at morally defensible positions — even on novel and unprecedented issues.
If we think that the work of professional scientists is important and that they should be held
accountable for actions that affect the welfare of others, we must ask what values and norms
undergird the practice of science, and by what standards professional practice should be judged.
Professions, including scientific professions, differ in the extent to which they have made explicit
the norms and values that govern professional practice. Some professions, such as engineering,
law, medicine, dentistry, and psychotherapy, have explicit codes of conduct, describing how the
profession’s ideals translate into specific expectations and obligations. Scientific societies (with
the possible exception of medical science) tend to simply set forth the organization’s aspirations or
ideals. For instance, in science, rather than speaking of professional obligations, professionals refer
to traditions or norms of practice. In its report, the National Academy of Sciences Panel on
Scientific Responsibility and the Conduct of Research observes that:
The community of scientists is bound by a set of values, traditions, and standards that embody
honesty, integrity, objectivity, and collegiality. These values are reflected in the particular
principles and practices characteristic of specific scientific disciplines.3
Scientists need practice in how to apply these values when formulating a response to one of the
practical ethical problems that frequently arise in the course of doing and presenting scientific
research. Some research indicates that skills of ethical reasoning are also a necessary condition for
excellence in practical problem solving.
For these reasons, we have concluded that training in decision making for young scientists
should devote considerable effort to developing and strengthening skills in ethical reasoning or
reflection. In turn, each person’s skills can be judged on the basis of his or her ability to develop a
well-reasoned response to the kinds of moral problems scientists encounter in professional life.
Judging responses to moral problems.
How does one decide whether a response is well-reasoned? What criteria apply? Can the
adequacy of a response to a moral problem be reliably judged? These are questions of concern to
students in an ethics course. Responses can be judged based on these criteria:
(A) Whether the response addresses each of the issues and points of ethical conflict presented in the case or problem;
(B) Whether each interested party’s legitimate expectations are considered;
2
 One of the more stunning examples is the 1976 case of Tarasoff v Regents of the University of California (17
C.3d425; [3] Cal.Rptr. 14,551 P.2d 334), wherein psychotherapists were held accountable for failing to warn Ms.
Tarasoff that her ex-boyfriend was making life-threatening statements about her during his counseling sessions. In
a wrongful death action brought against the Regents and psychotherapists at the university hospital by Tarasoff’s
parents, the California Supreme Court ruled that the duty to warn took precedence over the duty to protect the
client’s confidences, and held the professionals accountable — arguing that they should have recognized the
limitation of the duty to confidentiality — even though their profession’s code of ethics was not explicit on this
point. As a result, ethics courses for mental health professions routinely include cases patterned after Tarasoff.
3
 Panel on Scientific Responsibility and the Conduct of Research. Committee on Science, Engineering, and Public
Policy. National Academy of Sciences, National Academy of Engineering, Institute of Medicine. Responsible
Science: Ensuring the Integrity of the Research Process, Volume 1 (Washington, D.C.: National Academy Press,
1992), p.1.
Developing a Well-Reasoned Response / Page 2
(C) Whether the consequences of acting are recognized, specifically described (not just
generally mentioned), and incorporated into the decision; and
(D) Whether each of the duties or obligations of the protagonist are described and grounded
in moral considerations.
These are the criteria generally used to evaluate the adequacy of responses to ethical problems.
Persons with training in ethical analysis can reliably rate and rank the adequacy of the arguments
for a chosen response. The purpose of this paper is to help you understand the criteria for judging
the adequacy of moral arguments so you can develop a strong argument in defense of your position on the problem presented to you.
Case discussion
Before saying more about the criteria, let us address the process for a case discussion.
Step I. In a classroom setting you will be presented with a case study and you will be asked to
take a tentative position (e.g., “Yes, the protagonist should do something,” or “No, the protagonist should not do something”). In each case, you will focus on the protagonist and tell why (on
SIDE 1 of your response form) he or she should or should not do something.
As you read the problem, you may find yourself compiling a mental list of the issues involved,
like data ownership and access, collegial interactions, plagiarism, responsible use of animals,
authorship, confidentiality, data falsification, and the like. As you describe an issue, try to address
the point of conflict that each issue represents, e.g., a conflict of interests, rights, or needs of two
or more interested parties, conflicting obligations of the protagonist to other parties, or conflicting
values for the protagonist.
When you develop your response, focus on the reasons the protagonist should or should not
do something. Do not just pronounce an act as ethical or unethical; tell why you think so. In
considering why an action is acceptable or unacceptable, it may be helpful to consider:
• Who has a stake in the action?
• What might the consequences of the action be?
• What obligations might the protagonist have?
• What professional norms and values give rise to those obligations?
Note that each problem usually contains two or more issues; you should try to describe all of
them.
Step II. Participate in the discussion. During the discussion, you will have an opportunity to
hear what others think and learn what additional conflicts, interested parties, consequences, and
obligations they may have identified. You will also have an opportunity to ask questions of the
facilitator. Use this opportunity to expand your understanding of the issues, gain more information, and rethink your initial response to the problem(s) presented by the case.
Step III. When the discussion is finished, use SIDE 2 of your response form to either
strengthen or reformulate your response. At this point, you may change your mind on the position
you initially took if compelling arguments have been made to convince you to do so. You may
rewrite or simply refine your response. Note: You need not repeat points made on SIDE 1, and
you need not be concerned about errors of fact or reasoning made on SIDE 1, as long as you
Developing a Well-Reasoned Response / Page 3
address the error on SIDE 2. Notice that your response will also be evaluated according to your
willingness to reassess your position. Even if you do not change your mind about the correctness
of your position, you ought to be able to provide clearer reasons for maintaining that position. If
you do not change your mind about your position and no new arguments to support your
position occur to you after discussion, you still should not leave SIDE 2 blank. You should
at least address the arguments raised for other positions and explain why these arguments
are insufficient to make you change your mind.
Obviously, in some situations, there is little disagreement that one position is more defensible
than another, so it would be unlikely that people would disagree on the position itself. Responses
are evaluated based on the logical adequacy of the argument, not on whether you picked the
“correct position.” Remember, however, that one of the marks of a good scientist is the willingness to change one’s mind in the face of compelling reasons. It is not a virtue to “stand one’s
ground” when the evidence suggests a change of position is warranted.
Step IV. Turn in your paper for evaluation by your instructor. Your response will be read,
evaluated, and returned to you with suggestions as to how you might further strengthen your
argument.
Applying the criteria
The following are some additional suggestions to help you apply the criteria as you analyze an
ethically problematic situation and formulate a reasoned response.
1. Issues or points of conflict. To provide a convincing ethical analysis, you will want to
move beyond naming the issue (e.g., data ownership and access, plagiarism, etc.) to describing the
nature of the moral conflict. What constitutes an ethical conflict? A dilemma, by definition, is a
situation in which rights or obligations of interested parties conflict. For example, there’s a famous
hypothetical case called “Heinz and the Drug.” The scenario is this:
Heinz’s wife is dying. A cure is available from a druggist in Heinz’s town, who is the one who
discovered the drug, but the druggist charges much more for the drug than it costs him to
make it, and much more than Heinz can afford to pay. Heinz can’t raise the money and the
druggist will not agree to let him pay later.
The dilemma is whether Heinz should steal the drug to save his wife’s life. One issue in this case
has to do with property (whether the druggist’s right to his property should be respected), and
another has to do with life (whether Heinz is obliged to act to preserve his wife’s life). When we
examine the case in terms of conflicting rights, Heinz’s wife’s right to her life is in conflict with the
druggist’s right to his property. Heinz tried to resolve the problem without compromising either
the druggist’s or his wife’s rights and was unsuccessful. He exhausted his ability to resolve the
problem and is considering which of his conflicting obligations (to save his wife’s life or to respect
the druggist’s property) should take precedence.
Real-life dilemmas often present choices between equally unfavorable or disagreeable alternatives. Consider the case of the researcher considering data enhancement of preliminary findings to
assure continued funding for his research lab. He sees a conflict between his obligation to report
his data honestly and his obligation to secure enough funds to keep his lab technicians employed.
You might reason that honesty is a more important consideration than maintaining jobs for lab
Developing a Well-Reasoned Response / Page 4
technicians, but such practical considerations can influence professional judgment.
Note that identifying the points of ethical conflict is often one of the hardest jobs in ethical
analysis. Most people find it easier to begin by considering interested parties, consequences, and
obligations before trying to describe the issues more fully.
2. Interested parties. Skills in perspective-taking are called for by this criterion. Other parties, besides those directly mentioned in the case, may have a stake in the protagonist’s decision.
You might think of interested parties in progressively larger groupings, from the person facing the
ethical problem, to the person(s) immediately affected (such as that person’s students, teachers, or
research subjects), to the people in the relevant institution (the laboratory or university), to the
scientific community and society in general. Consider the reasonable expectations (rights) of each
interested party. Frequently, consideration of the interested parties will bring more issues to mind.
3. Consequences. For each action considered, there are often several possible outcomes. The
challenge in identifying consequences is not to identify every remote consequence, but to identify
those that have a good probability of occurring, or those that would have very serious consequences even if the probability of occurrence is not particularly high. For example, the possibility
that someone might die due to the release of a small amount of a toxic substance during an experimental procedure may be relatively remote, but the consequences would be so devastating that the
potential benefit may not even be worth a remote risk.
When considering consequences, be sure to consider, in turn, each of the interested parties and
the probable consequences of the proposed action on those parties. When considering consequences to the protagonist, keep in mind that consequences may be multifaceted. On the one
hand, he or she might get caught in an unethical act and face a lawsuit, loss of funding, loss of
reputation, or other serious negative consequences. On the other hand, he or she may get away
with an unethical act and get a publication or grant more easily and quickly than if he or she had
acted ethically. But whether or not the act is detected, engaging in actions we believe are wrong
undermines our sense of integrity. The effects of an action on a person’s character may appear to
be minor in the short run, but often have a cumulative and debilitating effect on one’s self-confidence, self-esteem, and habits — each time we reap the benefits of questionable acts and successful avoidance of the negative consequences, we enhance the probability that these acts will be
repeated.
4. Obligations. For each case, consider primarily the obligations of the protagonist toward the
various interested parties. It is sometimes tempting to dismiss the obligation of the protagonist
when some other person fails to live up to his/her moral obligation. For example, the protagonist
may reason as follows:
Everyone else fudges data points, and I’m competing with them for grants, so I have to (read:
am morally justified to) fudge my data, too.
One party’s failure to live up to his/her moral obligations can have an impact on another
party’s moral obligations, but this kind of reasoning often amounts to nothing more than a rationalization — an excuse to do whatever one wanted to do in the first place — without real regard
to the moral questions at hand.
Developing a Well-Reasoned Response / Page 5
When writing about the obligations of professionals such as scientists, it is not enough to say
that someone has a duty to do “x.” You must say why the professional has that duty. That is, you
should refer to the moral justification in terms of values, principles, character, or outcomes. For
example, consider the case of a researcher who is considering fabricating additional supporting
data to speed publication of an exciting preliminary result that could be very important in the
treatment of viral disease. In such a case, your reasoning might go something like this:
The scientist should not fabricate the data. Every scientist has a duty to report data truthfully
because honesty is one of the most fundamental values of science.
When describing ethical obligations, consider the various responsibilities of scientists. One
responsibility is to achieve at least the minimum standards of technical competence, and maintain
those standards during the course of professional practice. For example, scientists need to know
how to calibrate their instruments accurately. If you do not know how to calibrate a thermometer
properly, your experiment may be completely invalid. Given the right context and consequences,
lack of technical competence can become a moral issue. But even when we do know how to
calibrate instruments, there are honest mistakes, such as forgetting the calibration on one particularly hectic day, or mistakenly assuming your assistant did the calibration.
Each of us is fallible. This fact of human nature gives rise to another responsibility: In addition
to achieving and maintaining competence, one is expected to engage in responsible research
practices, like replication, proofreading, and peer review to guard against error. Responsible
research practice also includes the obligation to correct one’s technical errors, as well as errors of
interpretation and judgment.
In order to maintain the integrity of the research enterprise, almost every scientist will, at some
point, be asked to make distinctions: on one level, between honest error and honest differences of
interpretation and judgment; on another level, between negligent acts (e.g., mistakes resulting
from sloppy experimentation, poor scholarship, and other forms of negligent behavior) and intentional acts and misrepresentations, such as fabrication, falsification, or plagiarism. Scientists have
a responsibility to colleagues, to the research community, and to society to participate in the
monitoring of research practice. This means that the professional must be knowledgeable about
the process and procedures for dealing with allegations, and responsibly exercise his or her obligations to the accused and to the institution or scientific society in which the alleged misconduct is
discovered.
By considering this partial listing of the responsibilities of scientists, one gains an appreciation
of the complexity of moral issues that can arise in scientific practice.
Summary
In this paper, we have suggested that professionals, including professional scientists, have a
particular responsibility to have well-developed skills of moral reasoning. We briefly set forth the
following four criteria for evaluating the adequacy of a moral argument:
• Whether the response addresses each of the ethical issues and points of ethical conflict
presented in the case or problem.
• Whether each interested party’s legitimate expectations are considered.
Developing a Well-Reasoned Response / Page 6
• Whether the consequences of acting are recognized, specifically described (not just generally mentioned), and incorporated into the decision.
• Whether each of the obligations or duties of the protagonist are described and whether the
obligations are grounded in moral considerations.
Next, we described a four-step process for discussing case studies in research ethics in the
classroom:
Step I. Writing your response to the case.
Step II. Participating in discussion.
Step III. Refining your response.
Step IV. Turning in your response for assessment and feedback.
We concluded with an in-depth discussion of the four criteria, which we offer as a guide for
developing a well-reasoned response to a moral problem.
